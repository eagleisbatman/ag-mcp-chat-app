{
  "id": "0drNoQk1Uq9oukV8",
  "name": "AG-MCP Text-to-Speech",
  "nodes": [
    {
      "id": "webhook",
      "name": "TTS Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        240,
        300
      ],
      "webhookId": "tts-endpoint",
      "parameters": {
        "httpMethod": "POST",
        "path": "api/tts",
        "responseMode": "lastNode",
        "options": {}
      },
      "notes": "Receives TTS requests. Expects: { text, language, voice? }"
    },
    {
      "id": "prepare",
      "name": "Prepare TTS Request",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        560,
        500
      ],
      "parameters": {
        "jsCode": "// ====================================================================\n// AG-MCP TTS Voice Selection with Database-Driven Mappings\n// ====================================================================\n// IMPORTANT: Text is truncated to prevent TTS timeout on long responses\n// ====================================================================\n\nconst MAX_TEXT_LENGTH = 1500; // ~20-30 seconds of audio max\n\nconst rawText = $('TTS Webhook').item.json.body?.text || \"\";\nconst language = $('TTS Webhook').item.json.body?.language || \"en\";\nconst userVoice = $('TTS Webhook').item.json.body?.voice;\n\n// Truncate long text to prevent timeout\nlet text = rawText;\nlet wasTruncated = false;\nif (rawText.length > MAX_TEXT_LENGTH) {\n  // Find a good break point (end of sentence)\n  const truncateAt = rawText.lastIndexOf('.', MAX_TEXT_LENGTH);\n  if (truncateAt > MAX_TEXT_LENGTH / 2) {\n    text = rawText.substring(0, truncateAt + 1);\n  } else {\n    text = rawText.substring(0, MAX_TEXT_LENGTH) + '...';\n  }\n  wasTruncated = true;\n  console.log(`TTS: Truncated text from ${rawText.length} to ${text.length} chars`);\n}\n\n// Get voice mappings from API Gateway (if available)\nlet apiVoiceMapping = null;\nlet defaultVoiceFromAPI = 'Puck';\n\ntry {\n  const apiResponse = $('Fetch Voice Mappings').item.json;\n  if (apiResponse?.success && apiResponse?.mapping) {\n    apiVoiceMapping = apiResponse.mapping;\n    defaultVoiceFromAPI = apiResponse.defaultVoice || 'Puck';\n  }\n} catch (e) {\n  // API unavailable - use hardcoded\n}\n\n// Hardcoded fallback mapping\nconst hardcodedVoiceMap = {\n  'hi': 'Charon', 'te': 'Kore', 'kn': 'Puck', 'ta': 'Zephyr',\n  'mr': 'Charon', 'bn': 'Kore', 'gu': 'Puck', 'ml': 'Zephyr',\n  'pa': 'Charon', 'or': 'Kore', 'en': 'Puck', 'es': 'Charon'\n};\n\n// Voice selection: user > database > hardcoded > default\nlet voiceName;\nif (userVoice) {\n  voiceName = userVoice;\n} else if (apiVoiceMapping && apiVoiceMapping[language]?.voiceId) {\n  voiceName = apiVoiceMapping[language].voiceId;\n} else if (hardcodedVoiceMap[language]) {\n  voiceName = hardcodedVoiceMap[language];\n} else {\n  voiceName = defaultVoiceFromAPI;\n}\n\n// Language names\nconst languageNames = {\n  'hi': 'Hindi', 'te': 'Telugu', 'kn': 'Kannada', 'ta': 'Tamil',\n  'mr': 'Marathi', 'bn': 'Bengali', 'gu': 'Gujarati', 'ml': 'Malayalam',\n  'pa': 'Punjabi', 'or': 'Odia', 'en': 'English', 'es': 'Spanish'\n};\nconst langName = languageNames[language] || 'English';\n\n// Build TTS prompt\nlet prompt;\nif (language !== 'en') {\n  prompt = `Speak this in ${langName}, with a warm and friendly tone like a helpful agricultural advisor:\\n${text}`;\n} else {\n  prompt = `Speak with a warm and friendly tone like a helpful agricultural advisor:\\n${text}`;\n}\n\nreturn [{\n  json: {\n    text,\n    originalLength: rawText.length,\n    wasTruncated,\n    language,\n    voiceName,\n    prompt,\n    requestBody: {\n      contents: [{ parts: [{ text: prompt }] }],\n      generationConfig: {\n        responseModalities: [\"AUDIO\"],\n        speechConfig: {\n          voiceConfig: {\n            prebuiltVoiceConfig: { voiceName }\n          }\n        }\n      }\n    }\n  }\n}];"
      },
      "notes": "Selects TTS voice from database or hardcoded fallback"
    },
    {
      "id": "tts_api",
      "name": "Gemini TTS API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        780,
        500
      ],
      "parameters": {
        "method": "POST",
        "url": "=https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key={{ $env.GEMINI_API_KEY }}",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.requestBody) }}",
        "options": {
          "timeout": 60000
        }
      },
      "notes": "Calls Gemini 2.5 Flash Preview TTS with language-appropriate voice"
    },
    {
      "id": "response",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1000,
        500
      ],
      "parameters": {
        "jsCode": "const response = $json;\n\ntry {\n  const audioData = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;\n  if (!audioData) {\n    return [{ json: { success: false, error: \"No audio generated\" } }];\n  }\n  \n  // WAV file parameters (Gemini outputs 24kHz 16-bit mono PCM)\n  const sampleRate = 24000;\n  const numChannels = 1;\n  const bitsPerSample = 16;\n  \n  // Convert base64 PCM to Buffer\n  const pcmBuffer = Buffer.from(audioData, \"base64\");\n  const dataSize = pcmBuffer.length;\n  \n  // Create WAV header (44 bytes)\n  const wavHeader = Buffer.alloc(44);\n  wavHeader.write(\"RIFF\", 0);                              // ChunkID\n  wavHeader.writeUInt32LE(36 + dataSize, 4);               // ChunkSize\n  wavHeader.write(\"WAVE\", 8);                              // Format\n  wavHeader.write(\"fmt \", 12);                             // Subchunk1ID\n  wavHeader.writeUInt32LE(16, 16);                         // Subchunk1Size (PCM)\n  wavHeader.writeUInt16LE(1, 20);                          // AudioFormat (PCM=1)\n  wavHeader.writeUInt16LE(numChannels, 22);                // NumChannels\n  wavHeader.writeUInt32LE(sampleRate, 24);                 // SampleRate\n  wavHeader.writeUInt32LE(sampleRate * numChannels * bitsPerSample / 8, 28); // ByteRate\n  wavHeader.writeUInt16LE(numChannels * bitsPerSample / 8, 32);              // BlockAlign\n  wavHeader.writeUInt16LE(bitsPerSample, 34);              // BitsPerSample\n  wavHeader.write(\"data\", 36);                             // Subchunk2ID\n  wavHeader.writeUInt32LE(dataSize, 40);                   // Subchunk2Size\n  \n  // Combine header and PCM data\n  const wavBuffer = Buffer.concat([wavHeader, pcmBuffer]);\n  const wavBase64 = wavBuffer.toString(\"base64\");\n  \n  // Calculate duration in seconds\n  const bytesPerSecond = sampleRate * numChannels * bitsPerSample / 8;\n  const duration = Math.round(dataSize / bytesPerSecond);\n  \n  return [{\n    json: {\n      success: true,\n      audioBase64: wavBase64,\n      duration: duration,\n      mimeType: \"audio/wav\"\n    }\n  }];\n} catch (e) {\n  return [{ json: { success: false, error: e.message } }];\n}"
      },
      "notes": "Converts Gemini PCM audio to WAV format with proper headers"
    },
    {
      "id": "5d2c0221-3ad4-4134-9e2f-7972d7d2c3ca",
      "name": "Fetch Voice Mappings",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        350,
        500
      ],
      "parameters": {
        "method": "GET",
        "url": "={{ $env.API_GATEWAY_URL || 'https://ag-mcp-api-gateway.up.railway.app' }}/api/languages/tts-mapping",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "x-api-key",
              "value": "={{ $env.API_GATEWAY_KEY }}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "notes": "Fetches TTS voice mappings from database. Falls back to hardcoded if API fails.",
      "continueOnFail": true
    }
  ],
  "connections": {
    "Prepare TTS Request": {
      "main": [
        [
          {
            "node": "Gemini TTS API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini TTS API": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "TTS Webhook": {
      "main": [
        [
          {
            "node": "Fetch Voice Mappings",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Voice Mappings": {
      "main": [
        [
          {
            "node": "Prepare TTS Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "availableInMCP": true
  }
}
